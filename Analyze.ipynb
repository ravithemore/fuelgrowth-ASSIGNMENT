{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399bddc5-3d7b-4eae-9741-64ab807b3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video for Influencer 15...\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Saved unique face for Influencer 15 at influencer_faces\\15.jpg\n",
      "Processing video for Influencer 6...\n",
      "Saved unique face for Influencer 6 at influencer_faces\\6.jpg\n",
      "Saved unique face for Influencer 6 at influencer_faces\\6.jpg\n",
      "Processing video for Influencer 97...\n",
      "Saved unique face for Influencer 97 at influencer_faces\\97.jpg\n",
      "Processing video for Influencer 1...\n",
      "Saved unique face for Influencer 1 at influencer_faces\\1.jpg\n",
      "Saved unique face for Influencer 1 at influencer_faces\\1.jpg\n",
      "Processing video for Influencer 2...\n",
      "Saved unique face for Influencer 2 at influencer_faces\\2.jpg\n",
      "Saved unique face for Influencer 2 at influencer_faces\\2.jpg\n",
      "Saved unique face for Influencer 2 at influencer_faces\\2.jpg\n",
      "Saved unique face for Influencer 2 at influencer_faces\\2.jpg\n",
      "Saved unique face for Influencer 2 at influencer_faces\\2.jpg\n",
      "Processing video for Influencer 154...\n",
      "Saved unique face for Influencer 154 at influencer_faces\\154.jpg\n",
      "Saved unique face for Influencer 154 at influencer_faces\\154.jpg\n",
      "Processing video for Influencer 82...\n",
      "Saved unique face for Influencer 82 at influencer_faces\\82.jpg\n",
      "Processing video for Influencer 11...\n",
      "Saved unique face for Influencer 11 at influencer_faces\\11.jpg\n",
      "Saved unique face for Influencer 11 at influencer_faces\\11.jpg\n",
      "Processing video for Influencer 167...\n",
      "Saved unique face for Influencer 167 at influencer_faces\\167.jpg\n",
      "Saved unique face for Influencer 167 at influencer_faces\\167.jpg\n",
      "Processing video for Influencer 151...\n",
      "Saved unique face for Influencer 151 at influencer_faces\\151.jpg\n",
      "Saved unique face for Influencer 151 at influencer_faces\\151.jpg\n",
      "Processing video for Influencer 57...\n",
      "Saved unique face for Influencer 57 at influencer_faces\\57.jpg\n",
      "Saved unique face for Influencer 57 at influencer_faces\\57.jpg\n",
      "Processing video for Influencer 32...\n",
      "Saved unique face for Influencer 32 at influencer_faces\\32.jpg\n",
      "Processing video for Influencer 7...\n",
      "Saved unique face for Influencer 7 at influencer_faces\\7.jpg\n",
      "Processing video for Influencer 0...\n",
      "Saved unique face for Influencer 0 at influencer_faces\\0.jpg\n",
      "Processing video for Influencer 251...\n",
      "Saved unique face for Influencer 251 at influencer_faces\\251.jpg\n",
      "Saved unique face for Influencer 251 at influencer_faces\\251.jpg\n",
      "Saved unique face for Influencer 251 at influencer_faces\\251.jpg\n",
      "Saved unique face for Influencer 251 at influencer_faces\\251.jpg\n",
      "Saved unique face for Influencer 251 at influencer_faces\\251.jpg\n",
      "Processing video for Influencer 254...\n",
      "Saved unique face for Influencer 254 at influencer_faces\\254.jpg\n",
      "Saved unique face for Influencer 254 at influencer_faces\\254.jpg\n",
      "Processing video for Influencer 30...\n",
      "Saved unique face for Influencer 30 at influencer_faces\\30.jpg\n",
      "Saved unique face for Influencer 30 at influencer_faces\\30.jpg\n",
      "Processing video for Influencer 31...\n",
      "Saved unique face for Influencer 31 at influencer_faces\\31.jpg\n",
      "Processing video for Influencer 170...\n",
      "Saved unique face for Influencer 170 at influencer_faces\\170.jpg\n",
      "Saved unique face for Influencer 170 at influencer_faces\\170.jpg\n",
      "Processing video for Influencer 50...\n",
      "Saved unique face for Influencer 50 at influencer_faces\\50.jpg\n",
      "Saved unique face for Influencer 50 at influencer_faces\\50.jpg\n",
      "Saved unique face for Influencer 50 at influencer_faces\\50.jpg\n",
      "Saved unique face for Influencer 50 at influencer_faces\\50.jpg\n",
      "Processing video for Influencer 59...\n",
      "Saved unique face for Influencer 59 at influencer_faces\\59.jpg\n",
      "Processing video for Influencer 146...\n",
      "Saved unique face for Influencer 146 at influencer_faces\\146.jpg\n",
      "Processing video for Influencer 5...\n",
      "Saved unique face for Influencer 5 at influencer_faces\\5.jpg\n",
      "Saved unique face for Influencer 5 at influencer_faces\\5.jpg\n",
      "Saved unique face for Influencer 5 at influencer_faces\\5.jpg\n",
      "Processing video for Influencer 26...\n",
      "Saved unique face for Influencer 26 at influencer_faces\\26.jpg\n",
      "Saved unique face for Influencer 26 at influencer_faces\\26.jpg\n",
      "Processing video for Influencer 182...\n",
      "Saved unique face for Influencer 182 at influencer_faces\\182.jpg\n",
      "Processing video for Influencer 207...\n",
      "Saved unique face for Influencer 207 at influencer_faces\\207.jpg\n",
      "Saved unique face for Influencer 207 at influencer_faces\\207.jpg\n",
      "Processing video for Influencer 95...\n",
      "Saved unique face for Influencer 95 at influencer_faces\\95.jpg\n",
      "Saved unique face for Influencer 95 at influencer_faces\\95.jpg\n",
      "Saved unique face for Influencer 95 at influencer_faces\\95.jpg\n",
      "Saved unique face for Influencer 95 at influencer_faces\\95.jpg\n",
      "All videos processed and unique faces extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import requests\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "# File Paths\n",
    "csv_file = r\"C:\\Users\\cheta\\OneDrive\\Desktop\\sorted_unique_influencers_with_reliability.csv\" \n",
    "output_folder = \"influencer_faces\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to download and process video\n",
    "def download_and_process_video(video_url, influencer_id, known_face_encodings):\n",
    "    try:\n",
    "        video_response = requests.get(video_url, stream=True)\n",
    "        video_path = os.path.join(output_folder, f\"{influencer_id}.mp4\")\n",
    "        \n",
    "        with open(video_path, \"wb\") as video_file:\n",
    "            for chunk in video_response.iter_content(chunk_size=1024):\n",
    "                video_file.write(chunk)\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert to RGB for face recognition\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect faces\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            \n",
    "            for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "                # Check if the face is unique\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.6)\n",
    "                \n",
    "                if not any(matches):  # If this is a new unique face\n",
    "                    known_face_encodings.append(face_encoding)\n",
    "                    \n",
    "                    # Crop and save the face\n",
    "                    face_image = frame[top:bottom, left:right]\n",
    "                    face_image_path = os.path.join(output_folder, f\"{influencer_id}.jpg\")\n",
    "                    cv2.imwrite(face_image_path, face_image)\n",
    "                    print(f\"Saved unique face for Influencer {influencer_id} at {face_image_path}\")\n",
    "                    break\n",
    "            \n",
    "            # Stop processing further frames once a unique face is saved\n",
    "            if influencer_id in [os.path.splitext(f)[0] for f in os.listdir(output_folder)]:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        os.remove(video_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video for Influencer {influencer_id}: {e}\")\n",
    "\n",
    "# Known face encodings to avoid duplicates\n",
    "known_face_encodings = []\n",
    "\n",
    "# Processing each influencer\n",
    "for index, row in data.iterrows():\n",
    "    influencer_id = row[\"Influencer ID\"]\n",
    "    video_url = row[\"First Video URL\"]\n",
    "    print(f\"Processing video for Influencer {influencer_id}...\")\n",
    "    download_and_process_video(video_url, influencer_id, known_face_encodings)\n",
    "\n",
    "print(\"All videos processed and unique faces extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3f1e1d-cf6c-4a25-a62b-a5cca016ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF created successfully: influencer_table.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Image as ReportLabImage\n",
    "from reportlab.lib import colors\n",
    "from PIL import Image\n",
    "\n",
    "# File paths\n",
    "input_csv = r\"C:\\Users\\cheta\\OneDrive\\Desktop\\sorted_unique_influencers_with_reliability.csv\"  \n",
    "faces_folder =  r\"C:\\Users\\cheta\\OneDrive\\Desktop\\influencer_faces\"\n",
    "output_pdf = \"influencer_table.pdf\"\n",
    "\n",
    "data = pd.read_csv(input_csv)\n",
    "\n",
    "table_data = [[\"Influencer ID\", \"Image\", \"Average Performance\", \"Reliability\"]]\n",
    "\n",
    "# Function to resize image for the PDF\n",
    "def resize_image(image_path, width, height):\n",
    "    with Image.open(image_path) as img:\n",
    "        img.thumbnail((width, height))\n",
    "        resized_path = f\"{image_path}_resized.jpg\"\n",
    "        img.save(resized_path)\n",
    "        return resized_path\n",
    "\n",
    "# Iterate over the rows of the CSV\n",
    "for _, row in data.iterrows():\n",
    "    influencer_id = row[\"Influencer ID\"]\n",
    "    avg_performance = row[\"Average Performance\"]\n",
    "    reliability = row[\"Reliability\"]\n",
    "    \n",
    "    # Check if an image exists for the influencer\n",
    "    face_image_path = os.path.join(faces_folder, f\"{influencer_id}.jpg\")\n",
    "    if os.path.exists(face_image_path):\n",
    "        # Resize the image for better fitting in the table\n",
    "        resized_image_path = resize_image(face_image_path, 50, 50)\n",
    "        image = ReportLabImage(resized_image_path, width=50, height=50)\n",
    "    else:\n",
    "        image = \"No Image\"  # Incase of missing images\n",
    "    table_data.append([influencer_id, image, avg_performance, reliability])\n",
    "\n",
    "# Creating a PDF document\n",
    "pdf = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
    "elements = []\n",
    "\n",
    "# Creating the table\n",
    "table = Table(table_data)\n",
    "\n",
    "# Add style to the table\n",
    "style = TableStyle([\n",
    "    (\"BACKGROUND\", (0, 0), (-1, 0), colors.grey),\n",
    "    (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.whitesmoke),\n",
    "    (\"ALIGN\", (0, 0), (-1, -1), \"CENTER\"),\n",
    "    (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
    "    (\"FONTSIZE\", (0, 0), (-1, 0), 12),\n",
    "    (\"BOTTOMPADDING\", (0, 0), (-1, 0), 12),\n",
    "    (\"BACKGROUND\", (0, 1), (-1, -1), colors.beige),\n",
    "    (\"GRID\", (0, 0), (-1, -1), 1, colors.black),\n",
    "])\n",
    "\n",
    "table.setStyle(style)\n",
    "\n",
    "elements.append(table)\n",
    "\n",
    "pdf.build(elements)\n",
    "\n",
    "print(f\"PDF created successfully: {output_pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b6518-d8ba-477b-9c2b-48b5bf12dbee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
